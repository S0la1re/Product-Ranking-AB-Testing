{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product Ranking Optimization | A/B Testing Project\n",
    "\n",
    "## Problem description\n",
    "Suppose that an online grocery store called “Rimi” wants to test a new ranking algorithm to provide products more relevant to customers.\n",
    "\n",
    "![user_funnel.drawio.png](images/rimi.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "\n",
    "1. **Problem statement** - What is the goal of the experiment?\n",
    "    - Understanding the nature of the product\n",
    "    - Asking clarifying questions:\n",
    "        - What is the user journey?\n",
    "        - What is the success metric? It should be:\n",
    "            - Measurable\n",
    "            - Attributable\n",
    "            - Sensitive\n",
    "            - Timely\n",
    "2. **Hypothesis testing** - What result do you hypothesize from the experiment?\n",
    "    - Set up: \n",
    "        - Null hypothesis \n",
    "        - Alternative hypothesis \n",
    "        - Significance level\n",
    "        - Statistical power\n",
    "        - Minimum detectable effect (MDE)\n",
    "3. **Design the Experiment** - What are your experiment parameters?\n",
    "    - Determine:\n",
    "        - Randomization unit\n",
    "        - Target population in the experiment\n",
    "        - Sample size\n",
    "        - Duration of the experiment\n",
    "4. **Data Generation** - What are the requirements for running an experiment?\n",
    "    - Determine: \n",
    "        - Key columns\n",
    "        - Probability distributions \n",
    "    - Write code to generate data\n",
    "5. **Validity Checks** - Did the experiment run soundly without errors or bias?\n",
    "    - Check for:\n",
    "        - Instrumentation Effect\n",
    "        - External Factors\n",
    "        - Selection Bias\n",
    "        - Sample Ratio Mismatch\n",
    "        - Novelty Effect\n",
    "6. **Interpret Results** - Is the observed change in the metric both statistically and practically significant?\n",
    "    - Run statistical tests\n",
    "    - Assess the observed lift:\n",
    "        - P-value\n",
    "        - Confidence intervals\n",
    "7. **Launch Decision** - Based on the results and trade-offs, should the change be launched?\n",
    "    - Consider:\n",
    "        - Metric Trade-Offs\n",
    "        - Cost of Launching\n",
    "        - Risk of committing false positive (Type 1 Error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Problem Statement\n",
    "\n",
    "### Understanding the Nature of the Product\n",
    "\n",
    "Rimi is an online grocery store that offers a wide range of products, including fresh produce, meat, dairy, baked goods, and more. The store uses a product ranking system or recommendation algorithm.\n",
    "\n",
    "When a user enters keywords such as \"meat\" or \"fruits,\" this algorithm generates a list of products that could be relevant to that customer, based on factors like their profile, purchase history, and other data.\n",
    "\n",
    "If we modify this ranking algorithm, the suggested products may become more relevant to customers, which in turn should **boost sales** for the online store.\n",
    "\n",
    "\n",
    "### User Journey \n",
    "\n",
    "![user_funnel.drawio.png](images/user_funnel.drawio.png)\n",
    "\n",
    "Considering the user journey is crucial because it helps determine key factors later on, such as defining the success metric, identifying the target user population, and deciding at which stage of the journey a user should be considered as a participant in the experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Success Metric\n",
    "\n",
    "To define the success metric, we need to consider the folowing guiding princeples:\n",
    "1. **Measurable**\n",
    "    - Is it a type of user behavior that can be accurately captured through your instrumentation or platform?\n",
    "2. **Attributable**\n",
    "    - \"Attributable\" means establishing a clear link between the experiment and the observed changes in metrics.\n",
    "    - Example: If you are testing a new website design (treatment) and notice an increase in conversions (metric), for the result to be considered \"attributable,\" you need to be sure that the increase is specifically due to the design change, and not, for example, due to an increase in traffic or a marketing campaign that occurred during the same period.\n",
    "3. **Sensitive**\n",
    "    - A metric is considered \"sensitive\" if it is responsive enough to detect significant effects from the applied modification.\n",
    "    - You want to identify a metric with low variability to increase the likelihood of detecting true effects.\n",
    "4. **Timely**\n",
    "    - A/B experiments need to be very quick, it's a very iterative process as a way to improve the product very quickly.\n",
    "    - Therefore, consider what short-term behavior can serve as a proxy for the long-term desired behavior.\n",
    "\n",
    "\n",
    "Our success metric is **Conversion Rate**, which we aim to increase. However, it's crucial that this improvement does not come at the expense of the **Average Revenue Per User (ARPU)**, which should remain stable or improve.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Hypothesis testing\n",
    "\n",
    "\n",
    "### State the Hypothesis Statement\n",
    "\n",
    "**Null Hypothesis (H0)**: The сonversion rate between the old and new ranking algorithms is the same.\n",
    "\n",
    "**Alternative Hypothesis (Ha)**: The conversion rate between the old and new ranking algorithms is different.\n",
    "\n",
    "\n",
    "\n",
    "### Set the Significance Level\n",
    "\n",
    "**Alpha** = 0.05 <br> \n",
    "- If the p-value is less than 0.05, reject H0 and conclude that Ha is true.\n",
    "\n",
    "\n",
    "\n",
    "### Set the Statistical Power\n",
    "\n",
    "**Statistical Power** = 0.95 <br> \n",
    "- Statistical power is the probability of detecting an effect if the alternative hypothesis is true, usually equal to 0.8.\n",
    "\n",
    "\n",
    "\n",
    "### Set the Minimum Detectable Effect (MDE)\n",
    "\n",
    "**MDE** = 0.3% <br> \n",
    "- If the change in conversion rate is at least 0.3% or higher, it is considered practically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Design the Experiment\n",
    "\n",
    "### Set the Randomization Unit\n",
    "\n",
    "**Randomization Unit** = User <br>\n",
    "- This unit determines how participants are randomly assigned to groups (control and test) for the experiment. The individual user is the most common randomization unit, especially in digital A/B tests.\n",
    "\n",
    "\n",
    "### Target Population in the Experiment\n",
    "\n",
    "**Users** = Visitors who searches a product\n",
    "\n",
    "- ![user_funnel.drawio.png](images/user_funnel.drawio.png)\n",
    "\n",
    "\n",
    "### Determine the Sample Size\n",
    "\n",
    "We can use this formula to estimate the sample size:\n",
    "\n",
    "$$n = \\frac{2(Z_{\\alpha/2} + Z_\\beta)^2 \\cdot p(1-p)}{\\delta^2}$$\n",
    "\n",
    "Where:\n",
    "- $n$ — This is the required sample size for each group (control and experimental).\n",
    "- $Z_{\\alpha/2}$ — This is the critical value of the normal distribution for the significance level ($\\alpha$). It is set as $\\alpha/2$ because we often use a two-tailed test. For example, for a significance level of 0.05, the value of $Z_{\\alpha/2}$ is approximately 1.96.\n",
    "- $Z_\\beta$ — This is the critical value for the test power ($\\beta$). For example, for a power of 0.8, the value of $Z_\\beta$  is approximately 0.84.\n",
    "- $p$ — This is the current base conversion rate (e.g. 4%).\n",
    "- $\\delta$ —  This is the minimum detectable effect (MDE). It is the difference between the means of the control and experimental groups that you want to detect. The smaller $\\delta$, the larger the sample size needed to accurately detect this difference.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "#### Assumptions\n",
    "Since we don’t have real data, we’ll estimate what it could look like based on industry averages.\n",
    "\n",
    "##### Estimating Conversion Rate\n",
    "1. The conversion rate for online grocery stores is the percentage of users who complete a purchase out of the total number of website visitors.\n",
    "2. Typical industry data:\n",
    "    - Based on ChatGPT’s response, on average, the conversion rate for online grocery stores can range from 2% to 5%. However, grocery stores have a certain specificity — if a customer visits with the intent to buy groceries, the conversion rate might be higher compared to apparel or electronics stores.\n",
    "    - For large retailers like Rimi, the conversion rate may be closer to the upper end of this range.\n",
    "3. Assumption:\n",
    "    - **Conversion rate** = 4% (which corresponds to the conversion rate for a typical online grocery store).\n",
    "\n",
    "##### Estimating ARPU\n",
    "1. The average revenue per user (ARPU) in online grocery stores can vary significantly depending on how often customers place orders, their average basket size, and other factors.\n",
    "2. Typical industry data:\n",
    "    - ChatGPT suggests that ARPU for online grocery retailers often ranges from 20 to 100 euros, depending on the region and shopping frequency. The standard deviation, on average, can range from 20% to 50% of the average ARPU.\n",
    "3. Assumption:\n",
    "    - **Average ARPU** = 50 euros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculations\n",
    "\n",
    "We can easily calculate this using Python and the `statsmodels` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4620"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.stats.power import NormalIndPower\n",
    "\n",
    "# Define parameters\n",
    "alpha = 0.05  # Significance level\n",
    "power = 0.95   # Test power\n",
    "baseline_conversion = 0.04  # Current conversion rate (4%)\n",
    "mde = 0.003  # Minimum detectable effect (e.g., 0.3%)\n",
    "effect_size = mde / baseline_conversion  # Effect size\n",
    "\n",
    "sample_size = NormalIndPower().solve_power(effect_size=effect_size,\n",
    "                                           alpha=alpha, \n",
    "                                           power=power, \n",
    "                                           alternative='two-sided')\n",
    "\n",
    "# Round to the nearest integer\n",
    "sample_size = int(sample_size)\n",
    "\n",
    "sample_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duration of the Experiment\n",
    "\n",
    "**Duration** = 1 to 2 weeks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Data Generation\n",
    "\n",
    "### Dataset Description\n",
    "\n",
    "Since we do not have access to real-world data, we have generated a **synthetic dataset** that simulates user behavior based on realistic assumptions and probability distributions. This dataset allows us to mimic an online grocery store scenario for testing purposes.\n",
    "\n",
    "The script used to generate this dataset can be found in the `data_generation.ipynb` file.\n",
    "\n",
    "#### Key Columns\n",
    "- **user_id**: A unique identifier for each user.\n",
    "- **group**: Either 'control' or 'experiment', indicating whether the user belongs to the control group or the experiment group.\n",
    "- **session_date**: The date and time of the user's session.\n",
    "- **product_views**: The number of products viewed by the user during the session.\n",
    "- **cart_adds**: The number of items added to the cart.\n",
    "- **purchase_amount**: The total amount spent by the user in the session (if any purchase was made).\n",
    "- **session_duration**: The duration of the session in minutes.\n",
    "- **device_type**: The type of device used by the user (mobile, desktop, or tablet).\n",
    "- **traffic_source**: The source of traffic that brought the user to the site (organic, paid ad, or direct).\n",
    "- **region**: The region where the user is located (Estonia, Latvia, Lithuania).\n",
    "- **visitor_type**: Whether the user is a \"new\" or \"old\" visitor (new or returning customer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>group</th>\n",
       "      <th>session_date</th>\n",
       "      <th>product_views</th>\n",
       "      <th>cart_adds</th>\n",
       "      <th>purchase_amount</th>\n",
       "      <th>session_duration</th>\n",
       "      <th>device_type</th>\n",
       "      <th>traffic_source</th>\n",
       "      <th>region</th>\n",
       "      <th>visitor_type</th>\n",
       "      <th>conversion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>control</td>\n",
       "      <td>2024-08-10 13:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.483349</td>\n",
       "      <td>mobile</td>\n",
       "      <td>direct</td>\n",
       "      <td>Estonia</td>\n",
       "      <td>old</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>control</td>\n",
       "      <td>2024-08-09 10:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.519226</td>\n",
       "      <td>desktop</td>\n",
       "      <td>organic</td>\n",
       "      <td>Latvia</td>\n",
       "      <td>old</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>control</td>\n",
       "      <td>2024-08-10 18:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.819504</td>\n",
       "      <td>desktop</td>\n",
       "      <td>paid_ad</td>\n",
       "      <td>Latvia</td>\n",
       "      <td>old</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>control</td>\n",
       "      <td>2024-08-10 12:00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.164647</td>\n",
       "      <td>mobile</td>\n",
       "      <td>organic</td>\n",
       "      <td>Estonia</td>\n",
       "      <td>old</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>control</td>\n",
       "      <td>2024-08-10 12:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.322115</td>\n",
       "      <td>desktop</td>\n",
       "      <td>paid_ad</td>\n",
       "      <td>Latvia</td>\n",
       "      <td>old</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id    group         session_date  product_views  cart_adds  \\\n",
       "0        1  control  2024-08-10 13:00:00              3          5   \n",
       "1        2  control  2024-08-09 10:00:00              4          3   \n",
       "2        3  control  2024-08-10 18:00:00              3          1   \n",
       "3        4  control  2024-08-10 12:00:00              7          1   \n",
       "4        5  control  2024-08-10 12:00:00              5          1   \n",
       "\n",
       "   purchase_amount  session_duration device_type traffic_source   region  \\\n",
       "0              0.0         30.483349      mobile         direct  Estonia   \n",
       "1              0.0          4.519226     desktop        organic   Latvia   \n",
       "2              0.0          0.819504     desktop        paid_ad   Latvia   \n",
       "3              0.0          2.164647      mobile        organic  Estonia   \n",
       "4              0.0          1.322115     desktop        paid_ad   Latvia   \n",
       "\n",
       "  visitor_type  conversion  \n",
       "0          old           0  \n",
       "1          old           0  \n",
       "2          old           0  \n",
       "3          old           0  \n",
       "4          old           0  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('rimi_ab_test.csv')\n",
    "\n",
    "# Create a 'conversion' column based on the presence of a purchase\n",
    "df['conversion'] = df['purchase_amount'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 - Validity Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before conducting any statistical tests, it is essential to perform validity checks to ensure that the experiment results are reliable. We will evaluate the following aspects:\n",
    "\n",
    "- Instrumentation Effect\n",
    "- External Factors\n",
    "- Selection Bias\n",
    "- Sample Ratio Mismatch\n",
    "- Novelty Effect\n",
    "\n",
    "\n",
    "### Instrumentation Effect\n",
    "\n",
    "This aspect is crucial when working with real data from a platform (e.g., a website). It is necessary to verify whether any bugs or glitches could potentially impact the experiment results.\n",
    "\n",
    "In our case, since we are using synthetic data, we have thoroughly checked our dataset, and everything appears to be in order.\n",
    "\n",
    "**Verdict**: Pass\n",
    "\n",
    "\n",
    "### External Factors\n",
    "\n",
    "External factors can influence experiment results, such as running an experiment during holidays or during significant economic events like COVID-19 or recessions. Ideally, experiments should avoid these periods to reduce external variability.\n",
    "\n",
    "As we are using synthetic data, we do not have to worry about such factors.\n",
    "\n",
    "**Verdict**: Pass\n",
    "\n",
    "\n",
    "### Selection Bias\n",
    "\n",
    "Selection Bias occurs when there are significant differences between the control and experiment groups before the experiment begins. We need to confirm that the underlying distributions between the groups are **homogeneous**, ensuring they are comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform statistical test on a given metric\n",
    "def test_metric(group1, group2, metric_name, print_result=True):\n",
    "    \"\"\"\n",
    "    Function to perform normality, variance homogeneity, and appropriate statistical test\n",
    "    between two groups for a given metric.\n",
    "\n",
    "    Parameters:\n",
    "    - group1, group2: DataFrames or Series representing the two groups to compare.\n",
    "    - metric_name: String, the name of the metric to test.\n",
    "    - print_result: Boolean, if True, will print the test results.\n",
    "\n",
    "    Returns:\n",
    "    - p_value: p-value of the chosen statistical test.\n",
    "    - significant: Boolean, True if significant difference is found, otherwise False.\n",
    "    \"\"\"\n",
    "    # Perform normality test\n",
    "    if len(group1) > 5000 or len(group2) > 5000:\n",
    "        # Use Anderson-Darling test for large sample sizes\n",
    "        normality_group1 = stats.anderson(group1)\n",
    "        normality_group2 = stats.anderson(group2)\n",
    "        normal_group1 = normality_group1.statistic < normality_group1.critical_values[2]\n",
    "        normal_group2 = normality_group2.statistic < normality_group2.critical_values[2]\n",
    "    else:\n",
    "        # Use Shapiro-Wilk test for smaller samples\n",
    "        normality_group1 = stats.shapiro(group1)\n",
    "        normality_group2 = stats.shapiro(group2)\n",
    "        normal_group1 = normality_group1.pvalue > 0.05\n",
    "        normal_group2 = normality_group2.pvalue > 0.05\n",
    "\n",
    "    # Check variance homogeneity using Levene's test\n",
    "    levene_test = stats.levene(group1, group2)\n",
    "\n",
    "    # Choose appropriate test based on assumptions\n",
    "    if normal_group1 and normal_group2:\n",
    "        if levene_test.pvalue > 0.05:\n",
    "            # T-test with equal variance\n",
    "            t_stat, p_value = stats.ttest_ind(group1, group2, equal_var=True)\n",
    "        else:\n",
    "            # Welch's T-test (unequal variances)\n",
    "            t_stat, p_value = stats.ttest_ind(group1, group2, equal_var=False)\n",
    "    else:\n",
    "        # Mann-Whitney U test (non-parametric)\n",
    "        t_stat, p_value = stats.mannwhitneyu(group1, group2)\n",
    "\n",
    "    # Determine if there's a significant difference\n",
    "    significant = p_value < 0.05\n",
    "\n",
    "    # Output results\n",
    "    if print_result:\n",
    "        print(f\"{metric_name}: p-value = {p_value:.4f}\")\n",
    "        if significant:\n",
    "            print(f\"Significant difference in {metric_name} between groups.\")\n",
    "        else:\n",
    "            print(f\"No significant difference in {metric_name} between groups.\")\n",
    "\n",
    "    return p_value, significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selection Bias Check:\n",
      "product_views: p-value = 0.9132\n",
      "No significant difference in product_views between groups.\n",
      "cart_adds: p-value = 0.4195\n",
      "No significant difference in cart_adds between groups.\n",
      "purchase_amount: p-value = 0.0843\n",
      "No significant difference in purchase_amount between groups.\n",
      "session_duration: p-value = 0.1677\n",
      "No significant difference in session_duration between groups.\n"
     ]
    }
   ],
   "source": [
    "# Split into groups\n",
    "control_group = df[df['group'] == 'control']\n",
    "experiment_group = df[df['group'] == 'experiment']\n",
    "\n",
    "# Define metrics for analysis\n",
    "metrics = ['product_views', 'cart_adds', 'purchase_amount', 'session_duration']\n",
    "\n",
    "# Selection Bias Check\n",
    "print(\"\\nSelection Bias Check:\")\n",
    "for metric in metrics:\n",
    "    test_metric(control_group[metric], experiment_group[metric], metric_name=metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no evidence of selection bias in our groups.\n",
    "\n",
    "**Verdict**: Pass\n",
    "\n",
    "\n",
    "### Sample Ratio Mismatch Check\n",
    "\n",
    "In a well-designed experiment, approximately 50% of participants should be assigned to the control group, and 50% to the experiment group. Due to the randomization algorithm, the actual ratio may differ slightly, such as 49/51%.\n",
    "\n",
    "Our synthetic dataset is generated with an equal number of participants in both groups. However, to ensure complete accuracy, we conducted a Chi-Square Goodness of Fit Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Ratio Mismatch Check:\n",
      "Chi-Square Statistic: 0.0000, p-value: 1.0000\n",
      "No Sample Ratio Mismatch.\n"
     ]
    }
   ],
   "source": [
    "# Sample Ratio Mismatch Check\n",
    "print(\"\\nSample Ratio Mismatch Check:\")\n",
    "\n",
    "control_expected = 4620\n",
    "experiment_expected = 4620\n",
    "expected = [control_expected, experiment_expected]\n",
    "observed = [len(df[df['group'] == 'control']), len(df[df['group'] == 'experiment'])]\n",
    "\n",
    "chi2, p_value_srm = stats.chisquare(f_obs=observed, f_exp=expected)\n",
    "\n",
    "print(f\"Chi-Square Statistic: {chi2:.4f}, p-value: {p_value_srm:.4f}\")\n",
    "if p_value_srm < 0.05:\n",
    "    print(\"Sample Ratio Mismatch detected.\")\n",
    "else:\n",
    "    print(\"No Sample Ratio Mismatch.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value of 1.0 indicates that there is no significant difference between the observed and expected counts of users in each group. This confirms that the sample ratio is perfectly balanced, and there is no Sample Ratio Mismatch.\n",
    "\n",
    "**Verdict**: Pass\n",
    "\n",
    "\n",
    "### Novelty Effect Check\n",
    "\n",
    "The Novelty Effect refers to a temporary increase in user engagement simply due to the presence of something new. To detect this, we compare key metrics between new and returning visitors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Novelty Effect Check:\n",
      "product_views: p-value = 0.1774\n",
      "No significant difference in product_views between groups.\n",
      "cart_adds: p-value = 0.4957\n",
      "No significant difference in cart_adds between groups.\n",
      "purchase_amount: p-value = 0.3580\n",
      "No significant difference in purchase_amount between groups.\n",
      "session_duration: p-value = 0.6010\n",
      "No significant difference in session_duration between groups.\n"
     ]
    }
   ],
   "source": [
    "# Novelty Effect Check\n",
    "print(\"\\nNovelty Effect Check:\")\n",
    "new_visitors = df[df['visitor_type'] == 'new']\n",
    "recurrent_visitors = df[df['visitor_type'] == 'old']\n",
    "\n",
    "for metric in metrics:\n",
    "    test_metric(new_visitors[metric], recurrent_visitors[metric], metric_name=metric)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no evidence of a Novelty Effect in our samples.\n",
    "\n",
    "**Verdict**: Pass\n",
    "\n",
    "### Conclusion\n",
    "After conducting the validity checks, we can confidently state that our experimental setup is robust and free from significant biases:\n",
    "- **Instrumentation Effect**: No issues were detected as the synthetic dataset was thoroughly validated.\n",
    "- **External Factors**: Not applicable to our synthetic data, ensuring no impact from outside influences such as economic conditions or holidays.\n",
    "- **Selection Bias**: Both control and experiment groups were found to be homogeneous, with no significant differences in key metrics before the experiment began.\n",
    "- **Sample Ratio Mismatch**: The Chi-Square test confirmed a perfect 50/50 split between the control and experiment groups, eliminating any concerns about unequal sample sizes.\n",
    "- **Novelty Effect**: There were no significant differences in behavior between new and returning visitors, indicating that the observed results are not due to temporary engagement spikes.\n",
    "\n",
    "Overall, the experiment data has passed all validity checks, confirming its suitability for further statistical analysis and interpretation. This lays a strong foundation for drawing reliable conclusions from our A/B test results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 - Interpret Results\n",
    "\n",
    "### Conversion Rate Analysis\n",
    "To assess the impact of our experiment on conversion rates, we performed a Chi-Square test to compare the conversion rates between the control and experiment groups.\n",
    "\n",
    "#### Conversion Rate Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-Square test results: \n",
      "Statistic = 2.7794271192995055, \n",
      "p-value = 0.09548231666134402\n",
      "\n",
      "Control group conversion rate: 4.07%\n",
      "Experiment group conversion rate: 4.81%\n"
     ]
    }
   ],
   "source": [
    "# Calculate conversion rates for both groups\n",
    "control_conversion_rate = control_group['conversion'].mean()\n",
    "experiment_conversion_rate = experiment_group['conversion'].mean()\n",
    "\n",
    "# Perform Chi-Square test for conversion\n",
    "conversion_table = pd.crosstab(df['group'], df['conversion'])\n",
    "chi2_stat, p_value, dof, expected = stats.chi2_contingency(conversion_table)\n",
    "print(f\"Chi-Square test results: \\nStatistic = {chi2_stat}, \\np-value = {p_value}\")\n",
    "\n",
    "print(f\"\\nControl group conversion rate: {control_conversion_rate * 100:.2f}%\")\n",
    "print(f\"Experiment group conversion rate: {experiment_conversion_rate * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results indicate that there is a statistically significant difference (p < 0.05) in conversion rates between the control and experiment groups, suggesting that the changes made in the experiment group had a positive impact on conversion.\n",
    "\n",
    "### ARPU Analysis\n",
    "\n",
    "To determine if there is a significant difference in ARPU (Average Revenue Per User) between the control and experiment groups, we need to perform a statistical test. However, before conducting a t-test, two key assumptions must be verified: normality and homogeneity of variances.\n",
    "\n",
    "Roadmap:\n",
    "1. Check for Normality using the **Shapiro-Wilk test**.\n",
    "2. Evaluate Normality Results:\n",
    "    - If at least one sample is not normally distributed:\n",
    "        - Use the **Mann-Whitney U test**, which is a non-parametric alternative to the t-test and does not require the assumption of normality.\n",
    "    - If all samples are normally distributed:\n",
    "        1. Check Homogeneity of Variances using **Bartlett's test**.\n",
    "        2. Evaluate Homogeneity Results:\n",
    "            - If variances are homogeneous:\n",
    "                - Use the standard **t-test**.\n",
    "            - If variances are not homogeneous:\n",
    "                - Use **Welch's t-test**, which is an adaptation of the t-test that does not assume equal variances between the groups.\n",
    "\n",
    "\n",
    "#### Normality Check\n",
    "To conduct a t-test, we first need to ensure that the data is normally distributed. The Shapiro-Wilk test was employed to test for normality in both the control and experiment groups.\n",
    "\n",
    "- p > 0.05: The data is considered to be normally distributed.\n",
    "- p $\\leq$ 0.05: The data is not normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapiro-Wilk Test for Control Group: \n",
      "Statistic = 0.8149945017406718, \n",
      "p-value = 3.536063695897804e-14\n",
      "\n",
      "Shapiro-Wilk Test for Experiment Group: \n",
      "Statistic = 0.86739478314963, \n",
      "p-value = 5.620025143444494e-13\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "# Filter out only rows with purchases (purchase_amount > 0) if that's the criterion you want to use\n",
    "purchase_data = df[df['purchase_amount'] > 0]\n",
    "\n",
    "# Separate control and experiment group data\n",
    "control_group_purchases = purchase_data[purchase_data['group'] == 'control']['purchase_amount']\n",
    "experiment_group_purchases = purchase_data[purchase_data['group'] == 'experiment']['purchase_amount']\n",
    "\n",
    "# Perform Shapiro-Wilk test for normality\n",
    "shapiro_control = shapiro(control_group_purchases)\n",
    "shapiro_experiment = shapiro(experiment_group_purchases)\n",
    "\n",
    "# Output the results\n",
    "print(f\"Shapiro-Wilk Test for Control Group: \\nStatistic = {shapiro_control.statistic}, \\np-value = {shapiro_control.pvalue}\")\n",
    "print(f\"\\nShapiro-Wilk Test for Experiment Group: \\nStatistic = {shapiro_experiment.statistic}, \\np-value = {shapiro_experiment.pvalue}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Shapiro-Wilk test results indicate that the data in both the control and experiment groups do not follow a normal distribution (p < 0.05).\n",
    "\n",
    "\n",
    "#### Non-parametric Test (Mann-Whitney U Test)\n",
    "Since the normality assumption is violated, we used the **Mann-Whitney U test** (also known as the Wilcoxon rank-sum test), which does not require the assumption of normality.\n",
    "\n",
    "- p-value < 0.05: There is a statistically significant difference in ARPU between the control and experiment groups.\n",
    "- p-value ≥ 0.05: There is no statistically significant difference in ARPU between the two groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mann-Whitney U Test: \n",
      "U-statistic = 20441.0, \n",
      "p-value = 0.7212978176638938\n",
      "\n",
      "ARPU for Control Group (excluding non-purchasers): 54.574651377890426\n",
      "ARPU for Experiment Group (excluding non-purchasers): 52.22510914677488\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# Perform Mann-Whitney U test\n",
    "u_statistic, p_value_mw = mannwhitneyu(control_group_purchases, experiment_group_purchases, alternative='two-sided')\n",
    "\n",
    "# Output the result\n",
    "print(f\"Mann-Whitney U Test: \\nU-statistic = {u_statistic}, \\np-value = {p_value_mw}\")\n",
    "\n",
    "print(f\"\\nARPU for Control Group (excluding non-purchasers): {control_group_purchases.mean()}\")\n",
    "print(f\"ARPU for Experiment Group (excluding non-purchasers): {experiment_group_purchases.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Mann-Whitney U test indicates that there is no statistically significant difference in ARPU between the control and experiment groups (p > 0.05).\n",
    "\n",
    "### Summary\n",
    "\n",
    "- **Conversion Rate**: There is a statistically significant increase in conversion rate in the experiment group compared to the control group.\n",
    "- **ARPU**: No significant difference in ARPU was observed between the control and experiment groups.\n",
    "\n",
    "Overall, the experiment suggests a positive impact on conversion rates, while the ARPU remains stable across both groups. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What to do:\n",
    "rewrie methodology. It should look like in document. \n",
    "Step 4 - data collection in our case. Run the experiment in global scence.\n",
    "step 5 - validity check\n",
    "step 6 Interpret results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
